#summary Convert an OutputStream into an InputStream
#labels Draft

= Convert `OutputStream` to an `InputStream` =

If are programming using java streams, sometimes you'll find yourself in a situation in which a method creates data and writes them into an `OutputStream` and you need to use them in another method that expects to read the data from an `InputStream`.

Bad news: there is no (both easy and efficient) way to get the `OutputStream` to fit the `InputStream` interface or to get the first converted into the latter. However there are some different strategies: 
 * copy the data into a memory buffer (`ByteArrayOutputStream`) and read it again. This is the best approach if you're sure your data fits into memory.
 * copy your data to a temporary file and read it back.
 * use pipes: this is the best approach both for memory usage and speed (you can take full advantage of the multi-core processors) and also the standard solution offered by Sun.
 * use "circular buffers".
 * Use `InputStreamFromOutputStream` and `OutputStreamToInputStream` from this library.

== Copy the data into memory ==
This is the easiest approach if your data easily fit into memory. I don't recommend this approach if the data you're reading is more than 100Mb (because it's it's not the only one object in your heap and if you're in a web application 10-15 simultaneous users can easily eat up all your jvm heap). 

This approach also supports multiple reads of the same data:

{{{
  ByteArrayOutputStream out = new ByteArrayOutputStream();

  //write data on your OutputStream here
  writeDataOnTheOutputStream(out);

  byte[] data = out.toByteArray();
  ByteArrayInputStream istream = new ByteArrayInputStream(data);
  processDataFromInputStream(istream);
  //eventually you can use it twice:
  //processAgainDataFromInputSream(new ByteArrayInputStream(data));
}}}

== Copy your data into a temporary File ==
This is the easiest approach if you don't know in advance the size of data and you suspect it might be huge (>100Mb). 

The main disadvantages are :
 * It's utterly slow.
 * If used on large scale file handlers tend to finish.
 * File handlers might be a serious problem if you're not very careful closing all the streams: temporary files might not be deleted and file handlers might be still in use.

{{{
// create a temporary file.
File tempFile = File.createTempFile("tempFile", ".tmp");
OutputStream out = new FileOutputStream(tempFile);

// write data on your OutputStream here
writeDataOnTheOutputStream(out);
//be sure to close the OutputStream 
//(be sure the previous method doesn't throw exceptions)
out.close();
//get an InputStream from the previous file.
InputStream istream = new FileInputStream(tempFile);
				
//process the data as you like.				processDataFromInputStream(istream);

//be sure to close here.
istream.close();
//delete temporary file when you finish to use it.
//if streams where not correctly closed this might fail (return false)
tempFile.delete();
}}}
== Pipes ==
The two ends (`PipedInputStream` and `PipedOutputStream`) must be in two different `Threads`.

== Circular Buffers ==

== Use `InputStreamFromOutputStream` and `OutputStreamToInputStream` ==

This approach has many advantages:

 * These classes internally use pipes, so they have a fixed memory fingerprint (doesn't fill up your memory with data).
 * Details of threads are hidden from the user. You don't have to deal with instantiation/start/synchronization/stop. 
 * You can easily choose between many [ExecutionModel options] for instantiating new `Threads` (thread pool, thread per instance ...) or just don't care and get the default. 
 * Details of pipes are hidden. No  `PipeInputStream` or `PipeOutputStream` in your code.
 * The internal pipe size can be adjusted to fit your needs.

So if you like this last approach you read the [Tutorial_EasyStream tutorial] and see how to use these classes.